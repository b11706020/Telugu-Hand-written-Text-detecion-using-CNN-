{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca85b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5722d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c7b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, num_samples, data_dir, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[:num_samples]:\n",
    "            img_path, label = line.strip().split(' ')\n",
    "            img = load_img(os.path.join(data_dir, 'TeluguSeg/', img_path), target_size=image_size, color_mode='grayscale')\n",
    "            img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "    return np.array(images), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd01fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data_dir = \"C:/Users/saikiran.golla/Project/IIIT-HW-Telugu_v1.tar/IIIT-HW-Telugu_v1/TeluguSeg.tar/\"\n",
    "image_size = (128, 128)  # Adjust as needed\n",
    "num_training_samples = 60000\n",
    "num_validation_samples = 12000\n",
    "num_test_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59e26730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "230a203d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free memory: 547110912\n",
      "Used memory: 7712247808\n"
     ]
    }
   ],
   "source": [
    "free = psutil.virtual_memory()\n",
    "print(\"Free memory:\", free.free)\n",
    "print(\"Used memory:\", free.used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2917d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-30 19:59:05.278778\n"
     ]
    }
   ],
   "source": [
    "t_start = datetime.datetime.now()\n",
    "print(t_start)\n",
    "X_train, y_train = load_data(os.path.join(data_dir, 'train.txt'), num_training_samples,data_dir,image_size)\n",
    "X_val, y_val = load_data(os.path.join(data_dir, 'val.txt'), num_validation_samples,data_dir,image_size)\n",
    "X_test, y_test = load_data(os.path.join(data_dir, 'test.txt'), num_test_samples,data_dir,image_size)\n",
    "t_end = datetime.datetime.now()\n",
    "print(\"time taken :\",t_end-t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93c35793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train + y_val + y_test)\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ced0186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6282950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07a48db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12811\n"
     ]
    }
   ],
   "source": [
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d37a7a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your OCR model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(128, 128, 1)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')  # Use num_classes here\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "136a6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fec24f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 899s 479ms/step - loss: 9.4662 - accuracy: 1.0000e-04 - val_loss: 9.5798 - val_accuracy: 8.3333e-05\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 819s 437ms/step - loss: 9.3841 - accuracy: 2.0000e-04 - val_loss: 9.6604 - val_accuracy: 8.3333e-05\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 824s 439ms/step - loss: 9.3654 - accuracy: 2.3333e-04 - val_loss: 9.7397 - val_accuracy: 8.3333e-05\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 859s 458ms/step - loss: 9.3549 - accuracy: 2.3333e-04 - val_loss: 9.8177 - val_accuracy: 8.3333e-05\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1006s 536ms/step - loss: 9.3481 - accuracy: 2.3333e-04 - val_loss: 9.8945 - val_accuracy: 8.3333e-05\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1001s 534ms/step - loss: 9.3431 - accuracy: 2.3333e-04 - val_loss: 9.9693 - val_accuracy: 8.3333e-05\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1078s 575ms/step - loss: 9.3394 - accuracy: 2.3333e-04 - val_loss: 10.0409 - val_accuracy: 8.3333e-05\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1060s 565ms/step - loss: 9.3365 - accuracy: 2.3333e-04 - val_loss: 10.1070 - val_accuracy: 8.3333e-05\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1096s 585ms/step - loss: 9.3342 - accuracy: 2.3333e-04 - val_loss: 10.1657 - val_accuracy: 8.3333e-05\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 885s 472ms/step - loss: 9.3324 - accuracy: 2.3333e-04 - val_loss: 10.2153 - val_accuracy: 8.3333e-05\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train_encoded, validation_data=(X_val, y_val_encoded), epochs=25, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f1107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69bda69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 21s - loss: 10.3486 - accuracy: 2.0000e-04 - 21s/epoch - 66ms/step\n",
      "Test Accuracy: 0.0002\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded, verbose=2)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b212d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\saikiran.golla\\Project\\IIIT-HW-Telugu_v1.tar\\IIIT-HW-Telugu_v1\\TeluguSeg.tar\\TeluguSeg\\TeluguSeg\\train\\7\\296\\20.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a146978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 691ms/step\n",
      "Predicted Class: ౯౭\n"
     ]
    }
   ],
   "source": [
    "# Test the model on a new image\n",
    "new_image_path = \"C:/Users/saikiran.golla/Project/IIIT-HW-Telugu_v1.tar/IIIT-HW-Telugu_v1/TeluguSeg.tar/TeluguSeg/TeluguSeg/train/7/296/20.jpg\"\n",
    "new_image = load_img(new_image_path, target_size=image_size, color_mode='grayscale')\n",
    "new_image_array = img_to_array(new_image) / 255.0\n",
    "new_image_array = np.expand_dims(new_image_array, axis=0)\n",
    "predicted_class_index = model.predict(new_image_array).argmax()\n",
    "predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "print(f\"Predicted Class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c482367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('telugu_ocr_model_v8.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0780961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define your data directories and parameters\n",
    "data_dir = '/path/to/dataset'\n",
    "image_size = (128, 128)\n",
    "num_training_samples = 2000\n",
    "num_validation_samples = 500\n",
    "num_test_samples = 500\n",
    "\n",
    "# Load data\n",
    "def load_data(file_path, num_samples):\n",
    "    images = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[:num_samples]:\n",
    "            img_path, label = line.strip().split(' ')\n",
    "            img = load_img(os.path.join(data_dir, img_path), target_size=image_size, color_mode='grayscale')\n",
    "            img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "    return np.array(images), labels\n",
    "\n",
    "X_train, y_train = load_data(os.path.join(data_dir, 'train.txt'), num_training_samples)\n",
    "X_val, y_val = load_data(os.path.join(data_dir, 'val.txt'), num_validation_samples)\n",
    "X_test, y_test = load_data(os.path.join(data_dir, 'test.txt'), num_test_samples)\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train + y_val + y_test)\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Load and compile your model\n",
    "model = tf.keras.models.load_model('path_to_your_saved_model')\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_encoded, validation_data=(X_val, y_val_encoded), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded, verbose=2)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Test the model on a new image\n",
    "new_image_path = '/path/to/new/image.jpg'\n",
    "new_image = load_img(new_image_path, target_size=image_size, color_mode='grayscale')\n",
    "new_image_array = img_to_array(new_image) / 255.0\n",
    "new_image_array = np.expand_dims(new_image_array, axis=0)\n",
    "predicted_class_index = model.predict(new_image_array).argmax()\n",
    "predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "print(f\"Predicted Class: {predicted_class}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
